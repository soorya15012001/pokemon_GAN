{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrTDxg8s1692"
      },
      "source": [
        "!pip uninstall tensorflow\n",
        "!pip install tensorflow===2.3.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayvfIoYR5V5B"
      },
      "source": [
        "!unzip images.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYGT_U023di1"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from glob import glob\n",
        "from matplotlib import pyplot\n",
        "from sklearn.utils import shuffle\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0ynR9975Ewu"
      },
      "source": [
        "IMG_H = 128\n",
        "IMG_W = 128\n",
        "IMG_C = 3  ## Change this to 1 for grayscale.\n",
        "w_init = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rz5Wld1u_RIJ"
      },
      "source": [
        "def load_image(image_path):\n",
        "    img = tf.io.read_file(image_path)\n",
        "    img = tf.io.decode_png(img, channels=3)\n",
        "    img = tf.image.resize_with_crop_or_pad(img, IMG_H, IMG_W)\n",
        "    img = tf.cast(img, tf.float32)\n",
        "    img = (img - 127.5) / 127.5\n",
        "    return img"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e25iCqErjkEj",
        "outputId": "60b0f1e7-3e2a-41c7-e750-510bf786870c"
      },
      "source": [
        "load_image(\"/content/images/abomasnow.png\").shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([128, 128, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBCNb5ELAgl3"
      },
      "source": [
        "def tf_dataset(images_path, batch_size):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(images_path)\n",
        "    dataset = dataset.shuffle(buffer_size=10240)\n",
        "    dataset = dataset.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "    return dataset"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0f73eN7Gbgj"
      },
      "source": [
        "def deconv_block(inputs, num_filters, kernel_size, strides, bn=True):\n",
        "    x = Conv2DTranspose(\n",
        "        filters=num_filters,\n",
        "        kernel_size=kernel_size,\n",
        "        kernel_initializer=w_init,\n",
        "        padding=\"same\",\n",
        "        strides=strides,\n",
        "        use_bias=False\n",
        "        )(inputs)\n",
        "\n",
        "    if bn:\n",
        "        x = BatchNormalization()(x)\n",
        "        x = LeakyReLU(alpha=0.2)(x)\n",
        "    return x"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKRoySxfHzB7"
      },
      "source": [
        "def conv_block(inputs, num_filters, kernel_size, padding=\"same\", strides=2, activation=True):\n",
        "    x = Conv2D(\n",
        "        filters=num_filters,\n",
        "        kernel_size=kernel_size,\n",
        "        kernel_initializer=w_init,\n",
        "        padding=padding,\n",
        "        strides=strides,\n",
        "    )(inputs)\n",
        "\n",
        "    if activation:\n",
        "        x = LeakyReLU(alpha=0.2)(x)\n",
        "        x = Dropout(0.3)(x)\n",
        "    return x"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIhtEI-LI5_K"
      },
      "source": [
        "def build_generator(latent_dim):\n",
        "    f = [2**i for i in range(5)][::-1]\n",
        "    filters = 32\n",
        "    output_strides = 16\n",
        "    h_output = IMG_H // output_strides\n",
        "    w_output = IMG_W // output_strides\n",
        "\n",
        "    noise = Input(shape=(latent_dim,), name=\"generator_noise_input\")\n",
        "\n",
        "    x = Dense(f[0] * filters * h_output * w_output, use_bias=False)(noise)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    x = Reshape((h_output, w_output, 16 * filters))(x)\n",
        "\n",
        "    for i in range(1, 5):\n",
        "        x = deconv_block(x,\n",
        "            num_filters=f[i] * filters,\n",
        "            kernel_size=5,\n",
        "            strides=2,\n",
        "            bn=True\n",
        "        )\n",
        "    \n",
        "    x = conv_block(x,\n",
        "        num_filters=3,  ## Change this to 1 for grayscale.\n",
        "        kernel_size=5,\n",
        "        strides=1,\n",
        "        activation=False\n",
        "    )\n",
        "    fake_output = Activation(\"tanh\")(x)\n",
        "\n",
        "    return Model(noise, fake_output, name=\"generator\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHWbvvxgPet5"
      },
      "source": [
        "def build_discriminator():\n",
        "    f = [2**i for i in range(4)]\n",
        "    image_input = Input(shape=(IMG_H, IMG_W, IMG_C))\n",
        "    x = image_input\n",
        "    filters = 64\n",
        "    output_strides = 16\n",
        "    h_output = IMG_H // output_strides\n",
        "    w_output = IMG_W // output_strides\n",
        "\n",
        "    for i in range(0, 4):\n",
        "        x = conv_block(x, num_filters=f[i] * filters, kernel_size=5, strides=2)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(1)(x)\n",
        "\n",
        "    return Model(image_input, x, name=\"discriminator\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0xuGJzARMgF"
      },
      "source": [
        "class GAN(Model):\n",
        "    def __init__(self, discriminator, generator, latent_dim):\n",
        "        super(GAN, self).__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
        "        super(GAN, self).compile()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.loss_fn = loss_fn\n",
        "\n",
        "    def train_step(self, real_images):\n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "\n",
        "        for _ in range(2):\n",
        "            ## Train the discriminator - Fake Images\n",
        "            random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "            generated_images = self.generator(random_latent_vectors)\n",
        "            generated_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "            with tf.GradientTape() as ftape:\n",
        "                predictions = self.discriminator(generated_images)\n",
        "                d1_loss = self.loss_fn(generated_labels, predictions)\n",
        "            grads = ftape.gradient(d1_loss, self.discriminator.trainable_weights)\n",
        "            self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n",
        "\n",
        "            ## Train the discriminator - True Images\n",
        "            labels = tf.ones((batch_size, 1))\n",
        "\n",
        "            with tf.GradientTape() as rtape:\n",
        "                predictions = self.discriminator(real_images)\n",
        "                d2_loss = self.loss_fn(labels, predictions)\n",
        "            grads = rtape.gradient(d2_loss, self.discriminator.trainable_weights)\n",
        "            self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n",
        "\n",
        "        ## Train the generator\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "        misleading_labels = tf.ones((batch_size, 1))\n",
        "\n",
        "        with tf.GradientTape() as gtape:\n",
        "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
        "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
        "        grads = gtape.gradient(g_loss, self.generator.trainable_weights)\n",
        "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
        "\n",
        "        return {\"d1_loss\": d1_loss, \"d2_loss\": d2_loss, \"g_loss\": g_loss}\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NzZBGF6k2DK"
      },
      "source": [
        "def save_plot(examples, epoch, n):\n",
        "    examples = (examples + 1) / 2.0\n",
        "    for i in range(n * n):\n",
        "        pyplot.subplot(n, n, i+1)\n",
        "        pyplot.axis(\"off\")\n",
        "        pyplot.imshow(examples[i])  ## pyplot.imshow(np.squeeze(examples[i], axis=-1))\n",
        "    filename = f\"samples/generated_plot_epoch-{epoch+1}.png\"\n",
        "    pyplot.savefig(filename)\n",
        "    pyplot.close()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SnDqGB96oAL",
        "outputId": "cbdfae2c-1ce1-440c-bbeb-70d87409d99c"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    batch_size = 1\n",
        "    latent_dim = 128\n",
        "    num_epochs = 1000\n",
        "    images_path = glob(\"images/*\")\n",
        "\n",
        "    d_model = build_discriminator()\n",
        "    g_model = build_generator(latent_dim)\n",
        "\n",
        "\n",
        "    gan = GAN(d_model, g_model, latent_dim)\n",
        "    bce_loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True, label_smoothing=0.1)\n",
        "\n",
        "    d_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "    g_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "    gan.compile(d_optimizer, g_optimizer, bce_loss_fn)\n",
        "\n",
        "    images_dataset = tf_dataset(images_path, batch_size)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        gan.fit(images_dataset, epochs=60)\n",
        "        g_model.save(\"saved_model/g_model.h5\")\n",
        "        d_model.save(\"saved_model/d_model.h5\")\n",
        "\n",
        "        n_samples = 16\n",
        "        noise = np.random.normal(size=(n_samples, latent_dim))\n",
        "        examples = g_model.predict(noise)\n",
        "        save_plot(examples, epoch, int(np.sqrt(n_samples)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "809/809 [==============================] - 772s 954ms/step - d1_loss: 0.3141 - d2_loss: 0.2415 - g_loss: 2.7621\n",
            "Epoch 2/60\n",
            "809/809 [==============================] - 766s 947ms/step - d1_loss: 0.2035 - d2_loss: 0.2020 - g_loss: 2.8590\n",
            "Epoch 3/60\n",
            "809/809 [==============================] - 771s 953ms/step - d1_loss: 2.1598 - d2_loss: 5.3604 - g_loss: 4.1302\n",
            "Epoch 4/60\n",
            "809/809 [==============================] - 765s 946ms/step - d1_loss: 0.4606 - d2_loss: 0.3596 - g_loss: 1.7588\n",
            "Epoch 5/60\n",
            "809/809 [==============================] - 764s 944ms/step - d1_loss: 0.3613 - d2_loss: 0.2523 - g_loss: 2.4466\n",
            "Epoch 6/60\n",
            "809/809 [==============================] - 766s 947ms/step - d1_loss: 0.3763 - d2_loss: 0.2376 - g_loss: 2.5266\n",
            "Epoch 7/60\n",
            "809/809 [==============================] - 763s 944ms/step - d1_loss: 0.6419 - d2_loss: 0.4210 - g_loss: 2.4828\n",
            "Epoch 8/60\n",
            "809/809 [==============================] - 766s 947ms/step - d1_loss: 0.3067 - d2_loss: 0.2304 - g_loss: 2.5530\n",
            "Epoch 9/60\n",
            "809/809 [==============================] - 766s 947ms/step - d1_loss: 0.7361 - d2_loss: 0.5418 - g_loss: 2.4918\n",
            "Epoch 10/60\n",
            "809/809 [==============================] - 764s 944ms/step - d1_loss: 0.3236 - d2_loss: 0.2334 - g_loss: 2.5628\n",
            "Epoch 11/60\n",
            "809/809 [==============================] - 769s 951ms/step - d1_loss: 0.4346 - d2_loss: 0.2655 - g_loss: 2.6170\n",
            "Epoch 12/60\n",
            "809/809 [==============================] - 774s 957ms/step - d1_loss: 0.2832 - d2_loss: 0.2455 - g_loss: 2.6525\n",
            "Epoch 13/60\n",
            "809/809 [==============================] - 780s 964ms/step - d1_loss: 0.3028 - d2_loss: 0.2571 - g_loss: 2.7101\n",
            "Epoch 14/60\n",
            "809/809 [==============================] - 771s 954ms/step - d1_loss: 0.4520 - d2_loss: 0.3522 - g_loss: 3.7780\n",
            "Epoch 15/60\n",
            "809/809 [==============================] - 769s 951ms/step - d1_loss: 0.3015 - d2_loss: 0.2305 - g_loss: 2.5716\n",
            "Epoch 16/60\n",
            "809/809 [==============================] - 774s 957ms/step - d1_loss: 0.2716 - d2_loss: 0.2626 - g_loss: 2.8677\n",
            "Epoch 17/60\n",
            "809/809 [==============================] - 773s 956ms/step - d1_loss: 0.3175 - d2_loss: 0.2736 - g_loss: 2.8741\n",
            "Epoch 18/60\n",
            "809/809 [==============================] - 760s 940ms/step - d1_loss: 0.2699 - d2_loss: 0.2730 - g_loss: 2.8787\n",
            "Epoch 19/60\n",
            "809/809 [==============================] - 736s 909ms/step - d1_loss: 0.3255 - d2_loss: 0.3127 - g_loss: 2.9972\n",
            "Epoch 20/60\n",
            "809/809 [==============================] - 728s 900ms/step - d1_loss: 0.2642 - d2_loss: 0.2551 - g_loss: 2.7372\n",
            "Epoch 21/60\n",
            "809/809 [==============================] - 728s 900ms/step - d1_loss: 1.3682 - d2_loss: 0.6422 - g_loss: 4.3928\n",
            "Epoch 22/60\n",
            "809/809 [==============================] - 727s 898ms/step - d1_loss: 0.2652 - d2_loss: 0.2387 - g_loss: 2.8606\n",
            "Epoch 23/60\n",
            "809/809 [==============================] - 726s 897ms/step - d1_loss: 1.3295 - d2_loss: 2.4315 - g_loss: 3.2368\n",
            "Epoch 24/60\n",
            "809/809 [==============================] - 724s 895ms/step - d1_loss: 0.2971 - d2_loss: 0.2380 - g_loss: 2.8983\n",
            "Epoch 25/60\n",
            "809/809 [==============================] - 724s 895ms/step - d1_loss: 0.6582 - d2_loss: 0.4759 - g_loss: 3.0605\n",
            "Epoch 26/60\n",
            "809/809 [==============================] - 723s 894ms/step - d1_loss: 0.2659 - d2_loss: 0.2617 - g_loss: 2.8923\n",
            "Epoch 27/60\n",
            "809/809 [==============================] - 723s 893ms/step - d1_loss: 0.8184 - d2_loss: 0.4242 - g_loss: 2.9344\n",
            "Epoch 28/60\n",
            "809/809 [==============================] - 724s 895ms/step - d1_loss: 0.2731 - d2_loss: 0.2513 - g_loss: 2.7330\n",
            "Epoch 29/60\n",
            "809/809 [==============================] - 721s 891ms/step - d1_loss: 0.2881 - d2_loss: 0.2940 - g_loss: 3.1159\n",
            "Epoch 30/60\n",
            "809/809 [==============================] - 724s 894ms/step - d1_loss: 0.8579 - d2_loss: 0.5115 - g_loss: 3.6643\n",
            "Epoch 31/60\n",
            "809/809 [==============================] - 722s 893ms/step - d1_loss: 0.4346 - d2_loss: 0.2561 - g_loss: 2.8222\n",
            "Epoch 32/60\n",
            "809/809 [==============================] - 721s 891ms/step - d1_loss: 0.2626 - d2_loss: 0.2599 - g_loss: 2.9874\n",
            "Epoch 33/60\n",
            "809/809 [==============================] - 723s 894ms/step - d1_loss: 0.3354 - d2_loss: 0.2938 - g_loss: 3.0086\n",
            "Epoch 34/60\n",
            "809/809 [==============================] - 722s 893ms/step - d1_loss: 0.2699 - d2_loss: 0.3026 - g_loss: 3.0368\n",
            "Epoch 35/60\n",
            "809/809 [==============================] - 720s 890ms/step - d1_loss: 0.5733 - d2_loss: 0.6958 - g_loss: 2.9826\n",
            "Epoch 36/60\n",
            "809/809 [==============================] - 717s 887ms/step - d1_loss: 0.2377 - d2_loss: 0.2670 - g_loss: 3.0145\n",
            "Epoch 37/60\n",
            "809/809 [==============================] - 721s 892ms/step - d1_loss: 0.5954 - d2_loss: 2.5686 - g_loss: 3.6988\n",
            "Epoch 38/60\n",
            "809/809 [==============================] - 721s 891ms/step - d1_loss: 0.2799 - d2_loss: 0.2397 - g_loss: 2.8491\n",
            "Epoch 39/60\n",
            "809/809 [==============================] - 720s 890ms/step - d1_loss: 0.2403 - d2_loss: 0.2676 - g_loss: 3.0334\n",
            "Epoch 40/60\n",
            "809/809 [==============================] - 722s 892ms/step - d1_loss: 0.3310 - d2_loss: 0.3122 - g_loss: 3.1498\n",
            "Epoch 41/60\n",
            "809/809 [==============================] - 722s 893ms/step - d1_loss: 0.2948 - d2_loss: 0.2770 - g_loss: 3.0247\n",
            "Epoch 42/60\n",
            "514/809 [==================>...........] - ETA: 4:23 - d1_loss: 0.2693 - d2_loss: 0.3823 - g_loss: 3.1249"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}